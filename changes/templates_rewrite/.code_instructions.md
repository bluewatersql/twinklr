 Moving Head Sequencer Rewrite - Agent Instructions

## üìÅ Required Documentation (READ FIRST)

Before starting any work, access these documents in the project:

### Specifications (in `changes/templates_rewrite`)
- 01_core_concepts_foundations.md
- 02_configuration_rig_profiles.md
- 02_templates_methodology_design.md
- 03_logical_architecture_process.md
- 04_technical_architecture_design.md
- 05_current_system_migration.md
- README.md

### Implementation Plans (in `changes/templates_rewrite`)
- IMPLEMENTATION_PLAN_SUMMARY.md - START HERE
- IMPLEMENTATION_PLAN_PART1.md - Phase 0 tasks
- IMPLEMENTATION_PLAN_PART2.md - Phase 1 tasks
- IMPLEMENTATION_PLAN_PART3.md - Phases 2-6

## Progress Tracking

Current status is maintained in: `changes/templates_rewrite/working/AGENT_PROGRESS.md`

---

# Claude Code Agent Prompt - Moving Head Sequencer Rewrite

## Your Mission

You are implementing a complete rewrite of a moving head sequencer system following a detailed implementation plan. Your goal is to work through **60+ discrete tasks** across **6 phases**, building from foundational data models to a production-ready compilation pipeline.

---

## Critical Context Documents

Before starting ANY task, you MUST read and understand these documents (located in `changes/templates_rewrite`):

### Architecture & Specifications
1. **01_core_concepts_foundations.md** - Core contracts and design principles
2. **02_templates_methodology_design.md** - Template system design
3. **02_configuration_rig_profiles.md** - Rig configuration specification
4. **03_logical_architecture_process.md** - Pipeline architecture
5. **04_technical_architecture_design.md** - Technical standards and IR schema
6. **05_current_system_migration.md** - Migration approach
7. **README.md** - Specification overview

### Implementation Plan (located in `changes/templates_rewrite`)
1. **IMPLEMENTATION_SUMMARY.md** - **START HERE** - Overview, quick reference, critical decisions
2. **IMPLEMENTATION_PLAN_PART1.md** - Phase 0 tasks (foundational models)
3. **IMPLEMENTATION_PLAN_PART2.md** - Phase 1 tasks (curve operations)
4. **IMPLEMENTATION_PLAN_PART3.md** - Phases 2-6 (handlers, compilation, export)

### Working Documentation Directory (located in `changes/templates_rewrite/working`)
1. Organize working documents by folder (summary, handoffs, etc)
2. Include phase, task and document type in file names (Example: PHASE_0_TASK_1_1_SUMMARY.md)
---

## Your Working Process (MANDATORY)

### Step 1: Initialize Session
```markdown
Before starting any work:
1. Read IMPLEMENTATION_PLAN_SUMMARY.md completely
2. Identify current phase and task from progress tracking
3. Read the specification documents relevant to current phase
4. If refactoring or reusing current code:
    - Read and fully understand the code and its complete context
    - Check code for compliance to standards and remediate or rewrite as needed
4. Acknowledge understanding of current task requirements
```

### Step 2: Task Execution Loop

For EACH task, follow this EXACT sequence:

#### A. Task Preparation
```markdown
1. Read the full task specification from the implementation plan
2. Note all dependencies - verify they are marked complete
3. Review the "Actions" section - understand what to build
4. Study the "Code Template" - this is your starting point
5. Review "Test Requirements" - you will write these tests FIRST
6. Understand "Acceptance Criteria" - all must pass before task completion
```

#### B. Test-First Implementation
```markdown
1. Create test file FIRST (e.g., tests/core/curves/test_models.py)
2. Write ALL test cases listed in "Test Requirements"
3. Run tests - they should FAIL (no implementation yet)
4. Create implementation file (e.g., packages/blinkb0t/core/curves/models.py)
5. Start with code template from task specification
6. Implement until all tests pass
7. Run `mypy --strict` on new files - must pass with zero errors
8. Measure coverage - must meet task requirement (typically 95-100%)
```

#### C. Validation & Documentation
```markdown
1. Check EVERY acceptance criteria checkbox:
   - [ ] Are all ruff linting warnings and errors resolved?
   - [ ] Does mypy --strict pass? 
   - [ ] Do all N test cases pass?
   - [ ] Is coverage >= target%?
   - [ ] Do models serialize/deserialize correctly?
   - [ ] Are all docstrings present?
   
2. Generate artifacts:
   - Implementation file(s)
   - Test file(s)
   - Fixture files (if specified)
   
3. Document completion:
   - Mark all acceptance criteria as [x] complete
   - Update progress tracking document
   - Note any deviations or issues encountered
```

#### D. Task Completion Report
```markdown
After completing each task, provide a report:

## Task [X.Y] Completion Report

**Task:** [Name]
**Status:** ‚úÖ Complete / ‚ö†Ô∏è Partial / ‚ùå Blocked

### Artifacts Created
- [ ] packages/blinkb0t/core/.../[file].py
- [ ] tests/core/.../test_[file].py
- [ ] tests/fixtures/[fixture].json (if applicable)

### Acceptance Criteria Status
- [x] Criterion 1
- [x] Criterion 2
...
- [x] All criteria met

### Test Results
- Total tests: [N]
- Passed: [N]
- Coverage: [X]%
- Mypy errors: 0

### Issues Encountered
[None / Description of any deviations]

### Next Task
Ready to proceed to Task [X.Y+1]: [Name]
```

### Step 3: Phase Completion

When all tasks in a phase complete:

```markdown
1. Run phase exit checklist from implementation plan
2. Verify ALL exit criteria checkboxes can be marked
3. Run full test suite for the phase
4. Verify no regressions in earlier phases
5. Generate phase completion report
6. Request permission to proceed to next phase
```

---

## Code Quality Standards (NON-NEGOTIABLE)

### Type Safety
```python
# ‚úÖ ALWAYS DO THIS
from pydantic import BaseModel, Field, ConfigDict
from typing import Literal

class MyModel(BaseModel):
    model_config = ConfigDict(extra="forbid", frozen=True)
    value: float = Field(..., ge=0.0, le=1.0)

# ‚ùå NEVER DO THIS
class MyModel(BaseModel):
    value: float  # No validation
    # extra fields allowed (security risk)
```

### Import Style
```python
# ‚úÖ ALWAYS DO THIS (absolute imports)
from blinkb0t.core.curves.models import CurvePoint
from blinkb0t.core.sequencer.moving_heads.models.rig import RigProfile

# ‚ùå NEVER DO THIS (relative imports - hard review fail)
from .models import CurvePoint
from ..rig import RigProfile
```

### Immutability
```python
# ‚úÖ ALWAYS DO THIS
def apply_patch(base: dict, patch: dict) -> dict:
    result = deepcopy(base)
    # modify result
    return result

# ‚ùå NEVER DO THIS
def apply_patch(base: dict, patch: dict) -> dict:
    base.update(patch)  # Mutates input!
    return base
```

### Pure Functions
```python
# ‚úÖ ALWAYS DO THIS
def interpolate_linear(points: list[CurvePoint], t: float) -> float:
    """Pure function - no side effects."""
    # Calculate and return value
    return value

# ‚ùå NEVER DO THIS
cache = {}  # Module-level state
def interpolate_linear(points: list[CurvePoint], t: float) -> float:
    if t in cache:  # Stateful!
        return cache[t]
```

---

## Critical Architectural Rules

### Separation of Concerns
```
‚úÖ Templates describe choreography (no fixture IDs)
‚úÖ Rig profiles describe physical fixtures (no choreography)
‚úÖ Handlers generate curves (no orchestration)
‚úÖ Compiler orchestrates (no generation)
‚úÖ Exporters adapt output (no logic)

‚ùå NEVER mix these concerns
```

### Phase Offset Implementation
```python
# ‚úÖ MUST USE Option B (sampling-based)
def apply_phase_shift_samples(points, offset_norm, n_samples, wrap=True):
    t_grid = sample_uniform_grid(n_samples)
    for t in t_grid:
        t_shifted = (t + offset_norm) % 1.0 if wrap else clamp(t + offset_norm)
        v = interpolate_linear(points, t_shifted)
        # append to result
    return result

# ‚ùå NEVER use Option A (point mutation)
# This breaks composition and causes jitter
```

### Curve Composition Order
```python
# ‚úÖ CORRECT ORDER (mandatory)
1. Generate dense samples
2. Apply phase shift  
3. Apply envelopes / modulation / blends
4. Simplify (optional)

# ‚ùå WRONG ORDER
# Simplifying before phase shift distorts timing
```

---

## Decision-Making Framework

### When You Encounter Ambiguity

1. **Check specification documents first**
   - Search for relevant section in 01-05 docs
   - Look for examples in specs

2. **Check implementation plan**
   - Is there a code template?
   - Are there specific instructions?

3. **Follow patterns from completed tasks**
   - How was similar problem solved earlier?
   - What patterns are established?

4. **Choose the simpler approach**
   - Prefer explicit over implicit
   - Prefer pure functions over stateful
   - Prefer composition over inheritance

5. **Document uncertainty**
   - Note assumption in docstring
   - Flag for human review
   - Provide rationale for choice

### When Tests Fail

```markdown
1. Read test error message carefully
2. Check implementation against code template
3. Verify all validators are implemented
4. Check edge cases (empty lists, zero values, bounds)
5. Add print statements to debug
6. If stuck after 3 attempts, document issue and move to next solvable task
```

### When Mypy Fails

```markdown
1. Read mypy error carefully (line number, type mismatch)
2. Check that all Field() definitions have proper types
3. Verify ConfigDict is set correctly
4. Check for Optional[] types where None is allowed
5. Do NOT use # type: ignore unless absolutely necessary
6. If using # type: ignore, add comment explaining why
```

---

## Progress Tracking

### Maintain a Status Document

Create and update `AGENT_PROGRESS.md`:

```markdown
# Agent Progress Tracker

**Last Updated:** [Timestamp]
**Current Phase:** [0-6]
**Current Task:** [X.Y]

## Phase 0 - Foundations
- [x] Task 0.1: Project Structure Setup (2h) - ‚úÖ Complete
- [x] Task 0.2: Curve Schema Models (3h) - ‚úÖ Complete  
- [ ] Task 0.3: Channel and DMX Enums (1h) - üîÑ In Progress
- [ ] Task 0.4: IR Segment Model (4h)
- [ ] Task 0.5: Rig Profile Models (6h)
...

## Completed Tasks Summary
- Total: 2/60
- Phase 0: 2/10
- Phase 1: 0/6

## Current Focus
Working on Task 0.3 - Creating channel enums.
ETA: 30 minutes remaining.

## Blockers
None

## Notes
- All Phase 0 tasks so far passing mypy strict mode
- Test coverage consistently at 100%
```

---

## Example: Complete Task Execution

Let me show you what a complete task execution looks like:

### Task 0.2: Curve Schema Models

```markdown
## 1. PREPARATION (5 minutes)

Reading task specification...
- File: packages/blinkb0t/core/curves/models.py
- Tests: tests/core/curves/test_models.py
- Test count: 14 test cases required
- Coverage target: 100% branch coverage
- Key models: CurvePoint, PointsCurveSpec, NativeCurveSpec, CurveSpec

Dependencies: Task 0.1 ‚úÖ Complete

Code template provided in implementation plan.

## 2. TEST CREATION (20 minutes)

Creating tests/core/curves/test_models.py...

```python
import pytest
from pydantic import ValidationError
from packages.blinkb0t.core.curves.models import CurvePoint, PointsCurveSpec

def test_curve_point_valid_values():
    """Test CurvePoint accepts valid t and v in [0,1]."""
    p = CurvePoint(t=0.5, v=0.7)
    assert p.t == 0.5
    assert p.v == 0.7

def test_curve_point_rejects_t_below_zero():
    """Test CurvePoint rejects t < 0."""
    with pytest.raises(ValidationError) as exc:
        CurvePoint(t=-0.1, v=0.5)
    assert "t" in str(exc.value)

# ... (12 more test cases)
```

Running tests: FAILED (as expected - no implementation yet)

## 3. IMPLEMENTATION (60 minutes)

Creating packages/blinkb0t/core/curves/models.py...

Starting with code template from implementation plan...

```python
from pydantic import BaseModel, Field, ConfigDict, model_validator
from typing import Literal, Any

class CurvePoint(BaseModel):
    """A single point on a normalized curve."""
    model_config = ConfigDict(extra="forbid", frozen=True)
    
    t: float = Field(..., ge=0.0, le=1.0, description="Normalized time [0,1]")
    v: float = Field(..., ge=0.0, le=1.0, description="Normalized value [0,1]")

# ... (complete implementation)
```

## 4. VALIDATION (15 minutes)

Running tests:
```bash
pytest tests/core/curves/test_models.py -v
# 14 passed in 0.23s
```

Running mypy:
```bash
mypy --strict packages/blinkb0t/core/curves/models.py
# Success: no issues found
```

Measuring coverage:
```bash
pytest tests/core/curves/test_models.py --cov=packages.blinkb0t.core.curves.models
# Coverage: 100%
```

## 5. COMPLETION REPORT

### Task 0.2 Completion Report

**Task:** Curve Schema Models
**Status:** ‚úÖ Complete
**Duration:** 100 minutes

### Artifacts Created
- [x] packages/blinkb0t/core/curves/models.py (87 lines)
- [x] tests/core/curves/test_models.py (214 lines, 14 tests)

### Acceptance Criteria Status
- [x] `mypy --strict` passes with zero errors
- [x] 100% branch coverage on validators
- [x] All 14 test cases pass
- [x] Models serialize/deserialize to JSON correctly
- [x] No `# type: ignore` comments
- [x] Documentation strings present on all classes

### Test Results
- Total tests: 14
- Passed: 14
- Failed: 0
- Coverage: 100%
- Mypy errors: 0

### Issues Encountered
None - implementation followed code template precisely.

### Next Task
‚úÖ Ready to proceed to Task 0.3: Channel and DMX Enums
```

---

## Communication Protocol

### When Starting Work
```markdown
üöÄ **Starting Task [X.Y]: [Name]**

Dependencies verified: [List with checkmarks]
Reading specifications: [List docs]
Estimated duration: [X] hours
Target completion: [Timestamp]
```

### During Work (Every 30-60 minutes)
```markdown
üìä **Progress Update: Task [X.Y]**

Status: [Test creation / Implementation / Validation]
Progress: [X]% complete
Tests: [N] written, [M] passing
Issues: [None / Description]
On track: [Yes / No - explain if delayed]
```

### When Blocked
```markdown
üö´ **BLOCKED: Task [X.Y]**

Issue: [Clear description]
Attempted solutions:
1. [What was tried]
2. [What was tried]
3. [What was tried]

Relevant specs consulted: [List]
Error messages: [Paste exact errors]

Requesting: [Guidance / Clarification / Human review]
```

### When Complete
```markdown
‚úÖ **COMPLETED: Task [X.Y]**

Duration: [X] hours ([On time / +X mins / -X mins])
Artifacts: [List files with line counts]
Tests: [N] passing, Coverage: [X]%
Mypy: ‚úÖ Clean

Next: Ready for Task [X.Y+1]: [Name]
[or]
Next: Phase [X] complete - requesting phase review
```

---

## Phase-Specific Guidance

### Phase 0 (Tasks 0.1-0.10) - Foundations
**Focus:** Data models with validation, no behavior
**Key Skills:** Pydantic validators, Field constraints, model composition
**Common Pitfalls:** 
- Forgetting `extra="forbid"`
- Missing validators for cross-field validation
- Not testing all edge cases (empty strings, negative numbers, etc.)

### Phase 1 (Tasks 1.1-1.6) - Curves  
**Focus:** Pure mathematical functions, performance
**Key Skills:** Numerical algorithms, interpolation, recursion
**Common Pitfalls:**
- Not handling edge cases (empty lists, t=0, t=1)
- Mutating input lists
- Off-by-one errors in indexing
**Performance:** Must meet benchmarks or optimize

### Phase 2 (Tasks 2.1-2.6) - Handlers
**Focus:** Pure transformation functions, protocol adherence
**Key Skills:** Protocol implementation, registry pattern
**Common Pitfalls:**
- Adding orchestration logic to handlers
- Stateful handlers
- Not respecting rig calibration

### Phase 3 (Tasks 3.1-3.8) - Compilation
**Focus:** Orchestration, complex algorithms  
**Key Skills:** Immutable patching, scheduling, phase offset calculation
**Common Pitfalls:**
- Mutating source templates
- Off-by-one in repeat scheduling
- Incorrect phase offset distribution

**This is the MOST COMPLEX phase - take extra care**

### Phase 4 (Tasks 4.1-4.4) - Export
**Focus:** Format conversion, no logic
**Key Skills:** XML generation, DMX conversion
**Common Pitfalls:**
- Adding compilation logic to exporter
- Incorrect DMX value conversion

### Phase 5 (Tasks 5.1-5.3) - LLM
**Focus:** Minimal integration, validation
**Key Skills:** Schema design, response validation
**Common Pitfalls:**
- Overcomplicating LLM contract
- Not validating responses

### Phase 6 (Tasks 6.1-6.5) - Acceptance
**Focus:** End-to-end validation, cleanup
**Key Skills:** Integration testing, profiling
**Common Pitfalls:**
- Skipping performance profiling
- Not verifying dependency isolation

---

## Emergency Protocols

### If You Get Completely Stuck (After 3+ Hours)
1. Document exactly where you're stuck
2. Save all work in progress
3. Mark task as "Blocked"
4. Move to next independent task (check dependency graph)
5. Flag for human review

### If Tests Are Failing Mysteriously
1. Check Python version (must be 3.12)
2. Verify all dependencies installed
3. Check for typos in imports
4. Try running single test in isolation
5. Check for cached bytecode (delete __pycache__)

### If Mypy Produces Confusing Errors
1. Run mypy on single file to isolate issue
2. Check Pydantic version (must be V2)
3. Verify Field() types match attribute types
4. Check for circular imports
5. Consult mypy documentation for specific error code

---

## Success Metrics (Self-Check)

After each task, verify:
- [ ] All acceptance criteria checkboxes marked
- [ ] Zero mypy errors
- [ ] All tests pass
- [ ] Coverage meets target
- [ ] Code follows templates/patterns
- [ ] Docstrings present
- [ ] No code smells (mutations, globals, relative imports)

After each phase:
- [ ] Phase exit checklist complete
- [ ] No regressions in previous phases
- [ ] Performance benchmarks met (if applicable)
- [ ] Documentation updated

---

## Your First Actions (START HERE)

```markdown
1. Read IMPLEMENTATION_PLAN_SUMMARY.md completely
2. Read Phase 0 section of IMPLEMENTATION_PLAN_PART1.md
3. Read 01_core_concepts_foundations.md (specification)
4. Acknowledge your understanding with a summary of:
   - What you're building (high-level)
   - What Phase 0 accomplishes  
   - What Task 0.1 requires
5. Begin Task 0.1 execution
```

---

## Remember

- **You are not alone** - the specs and plan are comprehensive guides
- **Test first** - failing tests guide implementation
- **One task at a time** - don't skip ahead
- **Quality over speed** - better to do it right than fast
- **Document everything** - future you (or humans) will thank you
- **Ask for help** - if blocked after 3 hours, flag it

Your success is measured by:
1. **All acceptance criteria met** for each task
2. **Zero regressions** in previous work
3. **Clean code** that follows standards
4. **Comprehensive tests** with high coverage
5. **Complete documentation** of progress

You can do this. The plan is detailed, the templates are clear, and the architecture is sound. Work methodically, validate constantly, and you'll build something excellent.

**Now begin. Good luck! üöÄ**